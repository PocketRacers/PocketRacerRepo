
# Pocket Racer: Multi-Agent Autonomous Racing Platform

## Project Description
Pocket Racer is an innovative platform designed for simulating and training multi-agent autonomous racing models. Leveraging advanced transformer architectures, this platform enables the study and improvement of autonomous racing strategies in educational situations.

## Installation

To set up the Pocket Racer platform, please follow these steps:

```bash
# Clone the repository
git clone https://github.com/yourgithub/pocket-racer.git

# Navigate to the project directory
cd pocket-racer

# Install required dependencies
pip install -r requirements.txt
```

## Usage

To train the model using the provided scripts, you can run:

```bash
python train_script.py --epochs 50 --batch_size 1000
```

Modify the parameters as needed for your specific training setup.

## Features

- **Model Training**: Train vision transformers tailored for steering prediction.
- **Performance Metrics**: Evaluate model performance with metrics such as MAE, RMSE, and RÂ².
- **Customizable Training Options**: Configure training epochs, batch size, and image preprocessing through command-line arguments.

## Contributing

Contributions to Pocket Racer are welcome! Please consult the `CONTRIBUTING.md` file for guidelines on how to make contributions.

## License

This project is licensed under the MIT License - see the `LICENSE` file for details.

## Authors and Acknowledgment

- Eun Sang Cha
- Kittimate Chulajata
- Sean Wu
- Junu Choe
- Eric Laukien
- Dennis Hong*
- Daekyum Kim*

We thank all contributors who have helped in developing and refining this platform.
## Contact Information

For any queries or support, please contact [eunsang.cha@pepperdine.edu].
## Citation
If you use this software in your research, please cite it as follows:

```bibtex
@article{PocketRacer2024,
  title={Pocket Racer: An Accessible Platform for Multi-Agent Autonomous Racing},
  author={Cha, Eun Sang and Chulajata, Kittimate and Wu, Sean and Choe, Junu and Laukien, Eric and Hong, Dennis and Kim, Daekyum},
  journal={Nature Communications},
  year={2024},
  note={Submitted}
}

